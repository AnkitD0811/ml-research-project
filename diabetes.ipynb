{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1f720f2a-ca26-49d0-8aaf-e5c92220ff50",
   "metadata": {},
   "source": [
    "# Diabetes Dataset(Binary Classification)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fe30c5d-1366-40a5-8c63-06bcfdf28a23",
   "metadata": {},
   "source": [
    "## Initial Imports & Loading Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a8a611e-ebaf-4d87-adec-5fe31995ee3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing packages\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import sklearn\n",
    "import imblearn\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats.mstats import winsorize\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "from imblearn.over_sampling import RandomOverSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d709f1ce-42ff-4e18-9fa1-078336ed65f2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "\n",
    "dataset = pd.read_csv('datasets/diabetes.csv')\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9a6b238-7855-44fc-bc28-d5d08c30e441",
   "metadata": {},
   "source": [
    "## Visualizing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b488e447-7123-4a75-ad07-63e22ae35e00",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b75ac413-f9d7-4642-a212-187bd735aa37",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "## Visualizing Data\n",
    "\n",
    "fig, axes = plt.subplots(3, 3, figsize=(15, 15))\n",
    "axes = axes.flatten() \n",
    "\n",
    "for i, label in enumerate(dataset.columns[:-1]):\n",
    "    ax = axes[i]\n",
    "    ax.hist(dataset[dataset['Outcome'] == 1][label], \n",
    "            bins=15, color='blue', label='Diabetes', \n",
    "            density=True, alpha=0.5)\n",
    "    ax.hist(dataset[dataset['Outcome'] == 0][label], \n",
    "            bins=15, color='red', label='No Diabetes', \n",
    "            density=True, alpha=0.5)\n",
    "    ax.set_title(label)\n",
    "    ax.set_ylabel(\"Probability\")\n",
    "    ax.set_xlabel(label)\n",
    "    ax.legend()\n",
    "\n",
    "axes[8].bar(['Diabetes', 'No Diabetes'], \n",
    "        [len(dataset[dataset['Outcome'] == 1]['Glucose']), \n",
    "         len(dataset[dataset['Outcome'] == 0]['Glucose'])])\n",
    "axes[8].set_title('Diabetes vs No Diabetes')\n",
    "axes[8].set_ylabel('Number')\n",
    "\n",
    "plt.tight_layout()  # Adjust spacing between subplots\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8e70d6f-4a58-45a0-8bf6-8e06341079e6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Boxplots, best way to check for outliers\n",
    "\n",
    "fig, axes = plt.subplots(3, 3, figsize=(15, 15))\n",
    "axes = axes.flatten() \n",
    "\n",
    "for i, label in enumerate(dataset.columns[:-1]):\n",
    "    ax = axes[i]\n",
    "    ax.boxplot([dataset[dataset['Outcome'] == 1][label], dataset[dataset['Outcome'] == 0][label]], tick_labels=['Diabetes', 'No Diabetes'])\n",
    "    ax.set_title(label)\n",
    "\n",
    "plt.tight_layout()  # Adjust spacing between subplots\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d92eb33-d62f-4a01-9623-beb355e0b1c9",
   "metadata": {},
   "source": [
    "- There seem to be missing values here(0s) which need to be replaced. Since there are a lot of outliers,  mean will be affected but not median, hence we go with median as the replaced value. Mean works better for normal distributions and lower outlier scenarios.\n",
    "- There are a few outliers for certain features, they need to be handled properly.\n",
    "   - **Turkey's Rule**: Also called the Interquartile Range(IQR) rule. Here we calculate the range out of which the data points can be called outliers.\n",
    "         IQF = (Q3 - Q1)\n",
    "         Lower Boundary = (Q1 - 1.5 * IQR)\n",
    "         Upper Boundary = (Q3 + 1.5 * IQR). Other values instead of 1.5 like 2, 3 can also be used.\n",
    "   - **Drop the outliers**: Self explanatory. Can be done if a lot of rows, but not recommended as vulnerable record may get lost. Use only when you know that the data point is an incorrect rading, or when outliers represent data that is of no need(doesn't belong to the population), like outlier is data of a child but study is of adults.\n",
    "   - **Winsorize Method**: Limit Outliers by setting upper and lower limits. Especially useful for medical data where extreme but valid cases exist.\n",
    "   - **Log Transformation**: Mostly used on highly right-skewed data. It reduces the skewness of datya and tries to make it normal, which neural networks like a lot. However, log transformation may make the data more skewed in some cases. So be carefulwhen using it.\n",
    "- Divide the data into 3 sets - training, validation, test.\n",
    "- Also the dataset seems to imbalanced with there being much more cases of No diabetes than Diabetes. Oversampling needs to be done, but only on the training set.\n",
    "- Each feature has different range. We need to scale the training data properly."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99e7a98c-9ca7-4eb0-a087-dca78d0a1a5b",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50fd3d25-b242-4625-a70d-d59dde7c9f8c",
   "metadata": {},
   "source": [
    "### Remvoing Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aef05cf-1859-4c6a-80e0-571b0a39124b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Removing Missing Values(0s) in columns that make sense\n",
    "\n",
    "# Replacing 0 with Median to denote missing values\n",
    "missing = ['Glucose', 'BloodPressure', 'Insulin', 'BMI', 'SkinThickness']\n",
    "\n",
    "for col in missing:\n",
    "    dataset[col] = dataset[col].replace(0, dataset[col].median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a26ad11-c4a2-4b86-ae52-f28441ec9bfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boxplots, best way to check for outliers\n",
    "# To show no NaN values are left.\n",
    "\n",
    "fig, axes = plt.subplots(3, 3, figsize=(15, 15))\n",
    "axes = axes.flatten() \n",
    "\n",
    "for i, label in enumerate(dataset.columns[:-1]):\n",
    "    ax = axes[i]\n",
    "    ax.boxplot([dataset[dataset['Outcome'] == 1][label], dataset[dataset['Outcome'] == 0][label]], tick_labels=['Diabetes', 'No Diabetes'])\n",
    "    ax.set_title(label)\n",
    "\n",
    "plt.tight_layout()  # Adjust spacing between subplots\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8997ae83-9e4f-44b6-b6a2-afc387cf2a45",
   "metadata": {},
   "source": [
    "### Handling Outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28ca63d8-9c64-4f4d-b8d7-d270197b87ae",
   "metadata": {},
   "source": [
    "Taking care of outliers:\n",
    "\n",
    "1. Pregnancies: **Keep as is**. The dataset may be right skewed but thats normal, its expected for women to have lower number of pregnancies.\n",
    "2. Glucose: There is a strong chance the outliers here show hyperglycemia in diabetic patients. We want to preserve this information without letting it have extreme influence, this can be done by **Winsorization**. Log Transform will normalize the data which will lead to loss of iunformation.\n",
    "3. BloodPressure: Outliers may be measurement errors? **Winsorize** both ends.\n",
    "4. SkinThickness: Right-Skewed. Use **Log Transform**.\n",
    "5. Insulin: Heavily Right Skewed. **Log Transform** to be used.\n",
    "6. BMI: Moderately Skewed, Use **Winsorization**.\n",
    "7. DiabetesPedigreeFunction: **Winsorization**. This function contains genetic risk information where extreme values may represent legitimate hereditary factors. Mild winsorization preserves most information while reducing influence of extreme outliers\n",
    "8. Age: **Keep as is**. Cant be changed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ea7495b-9bff-4924-9bc5-24a316bb3807",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applying Outlier Handling Techniques\n",
    "\n",
    "# Winsorization\n",
    "for label in ['Glucose', 'BloodPressure', 'BMI', 'DiabetesPedigreeFunction', 'Insulin']:\n",
    "    lower = dataset[label].quantile(0.05)\n",
    "    upper = dataset[label].quantile(0.95)\n",
    "    dataset[label] = dataset[label].clip(lower, upper)\n",
    "\n",
    "# Log Transform\n",
    "# It won't work if the dataset has -ve values, which can be introduced after MICE Imputation\n",
    "# So clip these ones\n",
    "\n",
    "# dataset['Insulin'] = dataset['Insulin'].clip(lower=2)\n",
    "\n",
    "for label in ['SkinThickness', ]:\n",
    "    dataset[label] = np.log1p(dataset[label])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f72daea-79ef-43fd-a589-49732849e265",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Boxplots, best way to check for outliers\n",
    "\n",
    "fig, axes = plt.subplots(3, 3, figsize=(15, 15))\n",
    "axes = axes.flatten() \n",
    "\n",
    "for i, label in enumerate(dataset.columns[:-1]):\n",
    "    ax = axes[i]\n",
    "    ax.boxplot([dataset[dataset['Outcome'] == 1][label], dataset[dataset['Outcome'] == 0][label]], tick_labels=['Diabetes', 'No Diabetes'])\n",
    "    ax.set_title(label)\n",
    "\n",
    "plt.tight_layout()  # Adjust spacing between subplots\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bc61a1e-790e-4edc-a21f-2377834641b4",
   "metadata": {},
   "source": [
    "### Dataset Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e59fcaf5-6368-4f3e-99b8-4c868ec87889",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divide the dataset into features and targets\n",
    "\n",
    "x = dataset.drop('Outcome', axis=1)\n",
    "y = dataset['Outcome']\n",
    "\n",
    "x_train, x_new, y_train, y_new = train_test_split(x, y, test_size = 0.3, random_state = 0)\n",
    "x_valid, x_test, y_valid, y_test = train_test_split(x_new, y_new, test_size = 0.5, random_state = 0)\n",
    "\n",
    "temp = pd.concat([x_train, y_train], axis = 1)\n",
    "plt.bar(['Diabetes', 'No Diabetes'], \n",
    "        [len(temp[temp['Outcome'] == 1]['Glucose']), \n",
    "         len(temp[temp['Outcome'] == 0]['Glucose'])])\n",
    "plt.title('Diabetes vs No Diabetes')\n",
    "plt.ylabel('Number')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebde3c44-608d-4ca7-9828-909be9e9cf93",
   "metadata": {},
   "source": [
    "### Oversampling the training set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5022dfc4-7aea-458d-9e90-39f5331f9f4a",
   "metadata": {},
   "source": [
    "Oversampling/Undersampling is only done on the training data. Doing it on the other sets may cause data leakage. Thus, the data is divided first and then sampled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c87ea5cc-7e71-43a2-9dce-a24d694c06ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Oversampling the training set\n",
    "\n",
    "sampler = RandomOverSampler(sampling_strategy = 1)\n",
    "x_train, y_train = sampler.fit_resample(x_train, y_train)\n",
    "\n",
    "y_train.value_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aafed1a8-91b1-462f-b2c8-0956ff3a18e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = pd.concat([x_train, y_train], axis = 1)\n",
    "plt.bar(['Diabetes', 'No Diabetes'], \n",
    "        [len(temp[temp['Outcome'] == 1]['Glucose']), \n",
    "         len(temp[temp['Outcome'] == 0]['Glucose'])])\n",
    "plt.title('Diabetes vs No Diabetes')\n",
    "plt.ylabel('Number')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "447af292-0d4d-45a2-91c4-7a0dfb66460c",
   "metadata": {},
   "source": [
    "### Feature Scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa68f8cc-535f-4619-b14a-be957d3c7442",
   "metadata": {},
   "source": [
    "- Standardization is a common requirement for many ML algorithms as they start behaving badly if the individual features do not more or less look like standard normally distributed data: Gaussian with zero mean and unit variance.\n",
    "- In practice we often ignore the shape of the distribution and just transform the data to center it by removing the mean value of each feature, then scale it by dividing non-constant features by their standard deviation.\n",
    "\n",
    "1. StandardScaler: x_new = (x_old - mean) / (std deviation). This method is vulnerable to outliers as mean is affected by outliers. Zero Mean and Unit Variance, perfect for Neural Network Architectures.\n",
    "2. RobustScaler: x_new = (x_old - median) / (IQR). This uses median and is thus not affected by outliers. Since IQR is used as well, it absorbs the effects of outliers while scaling. If you have outliers that might affect the results and you don't want to remove them, use this.\n",
    "3. MinMaxScaler: x_new = (x_old - min_value) / (max_value - min_value). It sets data from 0 to 1. Not suitable when outliers are present as max and min values are used.\n",
    "4. MaxAbsScaler: x_new = x_old / |max_value|. If data has negative values, it sets data between -1 and 1. Since max value is used, it is not suitable for outliers.\n",
    "\n",
    "We will use a StandardScaler here. **UPDATE**: Changed to RobustScaler as it gives a much better Performance boost compared StandardScaler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16e00626-e084-4281-826a-7c8bb3d367e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Scaling\n",
    "\n",
    "scaler = RobustScaler()\n",
    "x_train = scaler.fit_transform(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0984ad1b-bdcd-468c-9035-1e662698742f",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_valid = scaler.transform(x_valid)\n",
    "x_test = scaler.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b1825fe-102a-43ab-bc04-172ff45647fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b95b30a1-07a0-46ac-b8a9-609a666b89be",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(x_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0db81d5f-483d-454c-b3af-382da98b4f2f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75324c86-a495-465a-9a94-500c84a14652",
   "metadata": {},
   "source": [
    "## Model Creation and Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a1f4d9c-1b94-48c7-99cf-a254e36d12f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Creation\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(units=35, activation='relu', kernel_regularizer=tf.keras.regularizers.L2(0.01)),\n",
    "    tf.keras.layers.Dense(units=25, activation='relu', kernel_regularizer=tf.keras.regularizers.L2(0.01)),\n",
    "    tf.keras.layers.Dense(units=15, activation='relu', kernel_regularizer=tf.keras.regularizers.L2(0.01)),\n",
    "    tf.keras.layers.Dense(units=1, activation='sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60d53f6a-1f8e-4f59-a9c0-5c0d70faf96b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "             loss = tf.keras.losses.BinaryCrossentropy(),\n",
    "             metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43df336d-6346-4186-9356-2ea59aa24c59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate initial performance without any training\n",
    "\n",
    "model.evaluate(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5802ff28-81b2-4171-8ecc-1ab9c55542b3",
   "metadata": {},
   "source": [
    "### Important Points"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e607bce5-7e52-4e7f-9971-27fef4dc03b2",
   "metadata": {},
   "source": [
    "- **Iterations**: Number of batches needed to complete one Epoch.\n",
    "- **Batch Size**: Number of training samples used in one Iteration.\n",
    "- **Epoch**: One full cycle through the entire dataset.\n",
    "- Number of steps per Epoch = Number of training examples / Batch Size\n",
    "- After every Iteration, weights are re-evaluated and updated. Batching is practical for efficient computation.\n",
    "\n",
    "Key Considerations to Keep in mind:\n",
    "\n",
    "- Too Many Epochs can lead to overfitting.\n",
    "- Smaller batch sizes introduce more noise but allow for more frequent updates. Larger batch sizes may require more memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1359b57-8485-477c-a16f-53b58bd6d7d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "\n",
    "model.fit(x_train, y_train, batch_size=64, epochs=25, validation_data=(x_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07509a9b-2753-4d86-8077-975fc4327fb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(x_test, y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2f47277-b0c4-43fc-8ce9-2e28f2a5b033",
   "metadata": {},
   "source": [
    "## Interim Results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7539d38b-1293-4eac-8bd3-ac0342aa1512",
   "metadata": {},
   "source": [
    "- We have acheived accuracy of 84.59% on our test data using the given simple neural network.\n",
    "- However, studies suggest that accuracy of upto 98% can be acheived. A simple neural network has provided a typical accuracy of 80-85% while Deep neural networks can acheive 88-98% accuracy.\n",
    "\n",
    "Some improvements include:\n",
    "\n",
    "1. Better Data Preprocessing\n",
    "   1. Changing the Scaler from StandardScaler to Robust Scaler resulted in accuracy to boost up by 2%.\n",
    "   2. Advanced Imputation Techniques for better handling of missing values. MICE helps preserve the relationship between variables better than blindly replacing with median value. \n",
    "   3. Advanced Class Balancing. Study ADASYN\n",
    "2. Hyperparameter Tuning\n",
    "3. More Layers(Deep Neural Network)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "852dab27-9669-440c-95e3-bb4c3a366720",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
